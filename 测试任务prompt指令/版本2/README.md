# 测试辅助指令模板使用流程 V2.0

**核心原则：**

*   **阶段化推进：** 按顺序执行需求分析、场景设计、代码生成。
*   **评审是关键：** 在关键节点（需求确认、场景确认）进行人工评审，确保质量和一致性。AI 评审辅助工具可用于提高效率，但不能替代人工决策。
*   **职责分离：** 每个模板专注于特定任务，根据需要选择合适的模板。

**流程步骤：**

1.  **【起点】 明确任务类型**
    *   判断您当前的任务是针对 **新功能** 的开发，还是需要为 **遗留代码** 补充测试或理解其行为。

2.  **【第一阶段】 需求理解与拆解**
    *   **情况 A: 新功能**
        *   **使用模板:** `新功能需求分析与拆解指令.md`
        *   **输入:** 提供产品需求文档（PRD）、用户故事（User Story）、业务流程描述、设计稿等。**务必确保输入包含清晰的验收标准（Acceptance Criteria）或业务规则。**
        *   **目标:** 让 AI 分析输入，将其拆解为结构化的 **特性 (Feature)** 或 **用户故事 (User Story)** 列表，每个单元包含明确的 **验收标准**。同时识别潜在的歧义或风险点。
        *   **输出:** 结构化的需求单元列表（包含特性/故事标题和详细的验收标准）。
    *   **情况 B: 遗留代码**
        *   **使用模板:** `遗留代码理解与需求提取指令.md`
        *   **输入:** 提供相关的源代码文件或代码片段，以及已知的上下文信息（如调用方式、主要职责）。
        *   **目标:** 让 AI 分析代码，识别其主要职责、关键逻辑、依赖关系、错误处理等，并尝试反向提取出可测试的 **系统行为描述**（可以用 Gherkin 风格输出）。
        *   **输出:** 代码分析报告和提取出的可测试行为描述列表。

3.  **【评审点 1 - 强制】 需求/行为确认评审**
    *   **评审对象:** 第 2 阶段输出的"需求单元列表"或"可测试行为描述"。
    *   **评审者:** 产品经理、业务分析师、开发负责人、测试负责人等相关干系人。
    *   **评审目标:**
        *   确认 AI 拆解/提取的需求/行为是否准确、完整地反映了原始意图（无论是文档还是代码）？
        *   验收标准/行为描述是否清晰、无歧义、可衡量、可测试？
        *   是否存在遗漏的关键点或业务规则？
        *   是否就所有识别出的歧义和风险点达成了一致？
        *   (对于代码提取) 是否准确反映了代码的核心逻辑和依赖？
    *   **辅助工具 (可选):** `评审辅助指令.md` (选择"类型 1: 评审需求单元")
        *   **输入:** 待评审的需求单元 + 原始依据（文档片段或代码）。
        *   **目标:** 让 AI 辅助检查一致性、清晰度、完整性，并提出疑问点，帮助评审者聚焦。
    *   **输出:** **经过评审和确认的**、清晰明确的需求单元/行为描述列表。**（这是进入下一阶段的前提）**

4.  **【第二阶段】 测试场景设计**
    *   **使用模板:** `测试场景生成指令.md`
    *   **输入:** 第 3 阶段 **评审确认后** 的需求单元/行为描述列表。
    *   **目标:** 基于每个确认的需求单元/行为描述，让 AI 使用 Gherkin 语言生成详细的测试场景（Scenario），覆盖核心成功路径、主要失败、边界和异常情况。
    *   **输出:** Gherkin 格式的 Feature 文件，包含多个 Scenario。

5.  **【评审点 2 - 强制】 测试场景评审**
    *   **评审对象:** 第 4 阶段输出的 Gherkin 测试场景。
    *   **评审者:** 测试工程师、开发工程师、产品经理/业务分析师。
    *   **评审目标:**
        *   Gherkin 场景是否清晰、易懂，准确反映了对应的需求单元/行为？
        *   场景是否全面覆盖了所有确认的验收标准/行为描述？
        *   场景是否充分考虑了正向、负向、边界和异常情况？
        *   场景描述的技术可行性如何？是否存在难以实现或验证的步骤？
        *   优先级（P0/P1/P2）和类型标注是否合理？
    *   **辅助工具 (可选):** `评审辅助指令.md` (选择"类型 2: 评审测试场景")
        *   **输入:** 待评审的 Gherkin 场景 + 对应的需求单元/验收标准。
        *   **目标:** 让 AI 辅助检查场景对需求的覆盖度、描述清晰度、常见边界遗漏等，并提出疑问。
    *   **输出:** **经过评审和确认的** Gherkin 测试场景集合。**（这是生成代码的前提）**

6.  **【第三阶段】 测试代码生成**
    *   **使用模板:** `测试代码生成指令.md`
    *   **输入:**
        *   第 5 阶段 **评审确认后** 的 Gherkin 测试场景。
        *   指定的测试框架（如 Jest, Pytest）。
        *   代码规范。
        *   [可选] 被测代码/API 的更详细信息（如果 Gherkin 不够明确）。
        *   [可选] 项目中使用的数据工厂或 Mock 库信息。
    *   **目标:** 让 AI 将确认的 Gherkin 场景转换为符合规范的可执行测试代码（主要是单元测试框架，根据场景也可生成集成测试骨架）。
    *   **输出:** 测试代码文件（如 `.spec.js`, `.test.py`）。

7.  **【评审点 3 - 标准实践】 代码评审 (Code Review)**
    *   **评审对象:** 第 6 阶段生成的测试代码。
    *   **评审者:** 团队中的其他开发或测试工程师。
    *   **评审目标:** 遵循团队标准的 Code Review 流程，检查代码的正确性、可读性、可维护性、性能、是否符合规范等。
    *   **输出:** 合并入代码库的可执行、高质量的测试代码。

**流程图示意：**

```mermaid
graph LR
    A[起点: 明确任务类型] --> B{新功能?};
    B -- Yes --> C[1a: 新功能需求分析];
    B -- No --> D[1b: 遗留代码分析];
    C --> E[评审点 1: 需求确认 (人工 + 可选AI辅助)];
    D --> E;
    E -- 确认通过 --> F[2: 测试场景生成 (Gherkin)];
    F --> G[评审点 2: 场景确认 (人工 + 可选AI辅助)];
    G -- 确认通过 --> H[3: 测试代码生成];
    H --> I[评审点 3: 代码评审 (标准实践)];
    I --> J[终点: 高质量测试代码];

    subgraph "模板使用"
        C --- T1a(模板 1a);
        D --- T1b(模板 1b);
        F --- T2(模板 2);
        H --- T3(模板 3);
    end

    subgraph "评审辅助 (可选)"
        E --- R1(模板 R - 类型1);
        G --- R2(模板 R - 类型2);
    end

    style E fill:#f9f,stroke:#333,stroke-width:2px;
    style G fill:#f9f,stroke:#333,stroke-width:2px;
    style I fill:#ccf,stroke:#333,stroke-width:1px;
``` 